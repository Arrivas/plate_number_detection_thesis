import torch
import numpy as np
import cv2
import time
import uuid
import os
import easyocr
import datetime
from gui import MainGui
import customtkinter
import threading
import pandas as pd
import pyaudio
import wave
import openpyxl

os.chdir(os.path.dirname(os.path.abspath(__file__)))
reader = easyocr.Reader(['en'], gpu=True)
class PlateDetection:

    def __init__(self, capture_index):
        self.capture_index = capture_index
        self.model = self.load_model()
        self.classes = self.model.names
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.duration = 5
        self.time_to_capture = 0
        print("Using Device: ", self.device)

    def get_video_capture(self):
        return cv2.VideoCapture(self.capture_index)

    def load_model(self):
        # model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True) old
        model = torch.hub.load("yolov5", 'custom', path="best.pt", source='local')
        # model = torch.hub.load("yolov7", 'custom', path_or_model="bestyolov7.pt", source='local')
        return model

    def score_frame(self, frame):
        self.model.to(self.device)
        frame = [frame]
        results = self.model(frame)
        labels, cord = results.xyxyn[0][:, -1], results.xyxyn[0][:, :-1]
        return labels, cord

    def class_to_label(self, x):
        return self.classes[int(x)]

    def filter_text(self, region, ocr_result):
        region_threshold = 0.040
        rectangle_size = region.shape[0]*region.shape[1]
        plate = [] 
        for result in ocr_result:
            length = np.sum(np.subtract(result[0][1], result[0][0]))
            height = np.sum(np.subtract(result[0][2], result[0][1]))
            if (length*height) / rectangle_size > region_threshold:
                plate.append(result[1])
        return plate

    def check_whitelist(self, plate_number):
      df = pd.read_excel('whitelist.xlsx')
      if plate_number in df['whitelist'].values:
          return True
      else:
          return False
      
    def play_wav(self, file_path):
        CHUNK = 1024
        wf = wave.open(file_path, 'rb')
        p = pyaudio.PyAudio()
        stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),
                        channels=wf.getnchannels(),
                        rate=wf.getframerate(),
                        output=True)

        data = wf.readframes(CHUNK)

        while len(data) > 0:
            stream.write(data)
            data = wf.readframes(CHUNK)

        stream.stop_stream()
        stream.close()
        p.terminate()
    
    
    def plot_boxes(self, results, frame):
        labels, cord = results
        n = len(labels)
        x_shape, y_shape = frame.shape[1], frame.shape[0]
        
        for i in range(n):
            row = cord[i]
            if row[4] >= 0.7:
                x1, y1, x2, y2 = int(row[0]*x_shape), int(row[1]*y_shape), int(row[2]*x_shape), int(row[3]*y_shape)
                color = (0, 255, 0)
                # draw rectangle together with the accuracy percentage
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                cv2.putText(frame, self.class_to_label(labels[i]), (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)
                cv2.putText(frame, f'{round(row[4].item()*100)}%', (x1, y1-20), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)
                cv2.putText(frame, f'capturing in {self.time_to_capture}', (x1, y1-60), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)
                if(self.time_to_capture == 0):
                    ocr_result = reader.readtext(frame[y1:y2, x1:x2])
                    plate = self.filter_text(frame[y1:y2, x1:x2], ocr_result)
                    # save as image
                    img_name = '{}.jpg'.format(uuid.uuid1())
                    # plate only
                    image_pos = frame[y1:y2, x1:x2]
                    # image_pos = frame
                    cv2.imwrite(os.path.join('./detected', img_name), image_pos)
                    time_stamp = datetime.datetime.now().strftime("%B, %d, %Y, %I:%M %p")
                    captured_image_directory = os.path.join('./detected', img_name)
                    # gui.add_captured_data(plate, time_stamp, captured_image_directory)
                    formatted_plate = ' '.join(plate)
                    print(formatted_plate, f'percentage: {round(row[4].item()*100)}%')
                    if self.check_whitelist(formatted_plate):
                      print("its in the whitelist")
                      gui.add_captured_data(plate, time_stamp, captured_image_directory, True)
                    else:
                      gui.add_captured_data(plate, time_stamp, captured_image_directory, False)
                      print("alert")
                      self.play_wav('beep.wav')
                    # print(os.path.join('D:\\Codes\python_\\thesis\\detected', img_name))
        
        return frame    
    

    def __call__(self):
        cap = self.get_video_capture()
        if not cap.isOpened():
            cap.open()
            assert cap.isOpened()
        start_time = time.time()
        while True:
            ret, frame = cap.read()
            # check if ret returns something
            assert ret
            results = self.score_frame(frame)
            frame = cv2.resize(frame, (600, 400))
            frame = self.plot_boxes(results, frame)

            end_time = time.time()
            fps = 1/np.round(end_time - start_time, 2)

            cv2.putText(frame, f'FPS: {int(fps)}', (20,70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)
            # cv2.putText(frame, f'capturing in {start_time-  time.time()}', (20,150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)
            cv2.imshow('Plate Number Detection', frame)
            # timer
            self.time_to_capture = int(self.duration-(time.time() - start_time))
            print(time.time() - start_time)
            if time.time() - start_time >= self.duration:
        # Save the image with timer
                start_time = time.time()
                print("save")
                
            if cv2.waitKey(5) & 0xFF == ord('q'):
                cap.release()
                break
        cv2.destroyAllWindows()


root = customtkinter.CTk()
width = 800
height = 500
root.title("Plate Number Detector | Thesis Group 1 BSCS-C")
screen_width = root.winfo_screenwidth()
screen_height = root.winfo_screenheight()
x = (screen_width/2) - (width/2)
y = (screen_height/2) - (height/2)
root.geometry("{}x{}+{}+{}".format(width, height, int(x), int(y)))
root.resizable(False, False)
customtkinter.set_appearance_mode=('dark')
customtkinter.set_default_color_theme('dark-blue')

def format_excel_captured():
     # arrange header
    df_edit = pd.read_excel('captured.xlsx')

    writer = pd.ExcelWriter('captured.xlsx', engine='openpyxl')
    df_edit.to_excel(writer, index=False)

    worksheet = writer.sheets['Sheet1']

    for i, column_name in enumerate(df_edit.columns):
        column_width = df_edit[column_name].astype(str).str.len().max()
        worksheet.column_dimensions[openpyxl.utils.get_column_letter(i + 1)].width = max(len(column_name), column_width) + 2

    writer.save()
    root.destroy()

def start_anpr():
  global t
  t = threading.Thread(target=detector)
  t.start()
    
gui = MainGui(root, start_anpr=start_anpr)

detector = PlateDetection(capture_index=0)
# root.after(100, start_anpr) http://192.168.137.209:4747/video?1920x1080
root.protocol("WM_DELETE_WINDOW", format_excel_captured)
root.mainloop()